{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dan's ACF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dan_acf(x, axis=0, fast=False):\n",
    "    \"\"\"\n",
    "    Estimate the autocorrelation function of a time series using the FFT.\n",
    "    :param x:\n",
    "        The time series. If multidimensional, set the time axis using the\n",
    "        ``axis`` keyword argument and the function will be computed for every\n",
    "        other axis.\n",
    "    :param axis: (optional)\n",
    "        The time axis of ``x``. Assumed to be the first axis if not specified.\n",
    "    :param fast: (optional)\n",
    "        If ``True``, only use the largest ``2^n`` entries for efficiency.\n",
    "        (default: False)\n",
    "    \"\"\"\n",
    "    x = np.atleast_1d(x)\n",
    "    m = [slice(None), ] * len(x.shape)\n",
    "\n",
    "    # For computational efficiency, crop the chain to the largest power of\n",
    "    # two if requested.\n",
    "    if fast:\n",
    "        n = int(2**np.floor(np.log2(x.shape[axis])))\n",
    "        m[axis] = slice(0, n)\n",
    "        x = x\n",
    "    else:\n",
    "        n = x.shape[axis]\n",
    "\n",
    "    # Compute the FFT and then (from that) the auto-correlation function.\n",
    "    f = np.fft.fft(x-np.mean(x, axis=axis), n=2*n, axis=axis)\n",
    "    m[axis] = slice(0, n)\n",
    "    acf = np.fft.ifft(f * np.conjugate(f), axis=axis)[m].real\n",
    "    m[axis] = 0\n",
    "    return acf / acf[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_run(x, y, id, savedir, saveplot=True):\n",
    "\n",
    "    gap_days = 0.02043365  # assume for long cadence\n",
    "    jump_arr = scipy.array([131.51139, 169.51883, 169.75000, 182.00000, 200.31000,\n",
    "                       231.00000, 246.19000, 256.00000, 260.22354, 281.00000,\n",
    "                       291.00000, 322.00000, 352.37648, 373.23000, 384.00000,\n",
    "                       398.00000, 443.48992, 475.50000, 504.00000, 539.44868,\n",
    "                       567.00000, 599.00000, 630.17387, 661.00000, 691.00000,\n",
    "                       711.20000, 735.36319, 762.00000, 808.51558, 845.00000,\n",
    "                       874.50000, 906.84469, 937.00000, 970.00000, 1001.20718,\n",
    "                       1032.50000, 1063.50000 ,1071.00000, 1093.60000])\n",
    "    \n",
    "    pylab.figure(1,(12, 9))\n",
    "    pylab.clf()\n",
    "    pylab.subplot(4,1,1)\n",
    "    pylab.title('ID: %s' %(id_list[0]), fontsize = 16)\n",
    "    pylab.axvspan(qt_max[j], qt_max[j+1], facecolor = 'k', alpha=0.1)\n",
    "    pylab.plot(x, y, 'k-')\n",
    "    for k in scipy.arange(len(jump_arr)):\n",
    "        pylab.axvline(jump_arr[k], ls = '--', c = 'b')\n",
    "    pylab.xlim(x.min(), x.max())\n",
    "    pylab.ylim(min(y[scipy.isfinite(y) == True]), \\\n",
    "               max(y[scipy.isfinite(y) == True]))\n",
    "    pylab.ylabel('Raw Flux')\n",
    "    pylab.subplot(4,1,2)\n",
    "    pylab.plot(x, y, 'k-')\n",
    "    pylab.xlim(x.min(), x.max())\n",
    "    pylab.ylim(x.min(), x.max())\n",
    "    pylab.ylabel('Norm Flux')\n",
    "\n",
    "    # max period searched for is len(flux) / 2\n",
    "    max_psearch_len = len(y) / 2.0\n",
    "\n",
    "    acf_tab, acf_per_pos, acf_per_height, acf_per_err, locheight, asym,  = \\\n",
    "        acf_calc(time=x, flux=y, interval=gap_days, kid = id, max_psearch_len = max_psearch_len)\n",
    "\n",
    "    pylab.figure(1)\n",
    "    pylab.subplot(4,1,4)\n",
    "    pylab.plot(acf_tab.lags_days, acf_tab.acf_smooth, 'k-')\n",
    "    pylab.axhline(0, ls = '--', c = 'k')\n",
    "    for i in scipy.arange(len(acf_per_pos)):\n",
    "        pylab.axvline(acf_per_pos[i], ls = '--', c = 'b')\n",
    "    pylab.ylabel('ACF')\n",
    "    pylab.xlim(0, acf_tab.lags_days.max())\n",
    "\n",
    "    pylab.figure(12)\n",
    "    pylab.clf()\n",
    "    pylab.plot(acf_tab.lags_days, acf_tab.acf_smooth, 'k-')\n",
    "    for m in scipy.arange(len(acf_per_pos)):\n",
    "        pylab.axvline(acf_per_pos[m], ls = '--', c = 'r')\n",
    "\n",
    "    # plot and calculate acf peak statistics\n",
    "    if acf_per_pos[0] != -9999:\n",
    "        med_dlag_per[x], dlag_per_err[x], acf_peak_per[x], h1[x], w1[x], lh1[x], \\\n",
    "            hlocgrad[x], hloc_grad_scatter[x], width_grad[x], width_grad_scatter[x], \\\n",
    "            num_of_peaks[x], harmonic_det[x], sel_peaks, one_peak_only, peak_ratio =\\\n",
    "            plot_stats(lc_tab.time, lc_tab.flux, x, acf_per_pos, \\\n",
    "                       acf_per_height, acf_per_err, locheight, asym)\n",
    "\n",
    "        n_s = 'k'\n",
    "\n",
    "        period[x] = acf_peak_per[x]\n",
    "#         print('PEAK RATIO = ', peak_ratio)\n",
    "\n",
    "        # plot period lines on full plot\n",
    "        pylab.figure(1)\n",
    "        pylab.subplot(4,1,4)\n",
    "        if med_dlag_per[x] >0:\n",
    "            for n in scipy.arange(len(sel_peaks)):\n",
    "                pylab.axvline(sel_peaks[n], ls = '--', c = 'r')\n",
    "        #pylab.axvline(period[x], ls = '--', c = 'k')\n",
    "        pylab.axvline(period[x], ls = '--', c = n_s)\n",
    "        if med_dlag_per[x] > 0:\n",
    "            pylab.axvspan(med_dlag_per[x]-dlag_per_err[x], \\\n",
    "                          med_dlag_per[x]+dlag_per_err[x],\\\n",
    "                facecolor = 'k', alpha=0.2)\n",
    "        pylab.xlim(period[x] * 10)\n",
    "\n",
    "        # variability stats\n",
    "        print('calculating var for P_med...')\n",
    "        amp_all[x], amp_per[x], per_cent, var_arr_real = \\\n",
    "            calc_var(kid = x, time_in = lc_tab.time, \\\n",
    "                     flux = lc_tab.flux, period = acf_peak_per[x])\n",
    "\n",
    "        pylab.figure(1)\n",
    "        pylab.subplot(4,1,3)\n",
    "        pylab.plot(per_cent, var_arr_real, 'k.')\n",
    "        pylab.axhline(amp_per[x], ls = '--', c = 'b')\n",
    "        pylab.xlim(lc_tab.time.min(),lc_tab.time.max())\n",
    "        pylab.ylim(var_arr_real.min(), var_arr_real.max())\n",
    "        ax = pylab.gca()\n",
    "        pylab.text(0.415, -0.15, 'Time (days)', transform = ax.transAxes)\n",
    "        pylab.text(0.415, -1.4, 'Period (days)', transform = ax.transAxes)\n",
    "        pylab.ylabel('Amplitudes')\n",
    "        pylab.xlim(period[x] * 10)\n",
    "\n",
    "        if saveplot:\n",
    "            print(\"saving figure\", \"%s/%s_full.png\" % (savedir, id_list[0]))\n",
    "            pylab.savefig('%s/%s_full.png' %(savedir, id_list[0]))\n",
    "\n",
    "        maxpts = 40.0\n",
    "        if scipy.floor(lc_tab.time.max() / acf_peak_per[x]) < maxpts:\n",
    "            maxpts = float(scipy.floor(lc_tab.time.max() / acf_peak_per[x]))\n",
    "        inc = lc_tab.time - lc_tab.time.min() <= (maxpts*acf_peak_per[x])\n",
    "\n",
    "#         print('**************************', 'KID = ', x, 'PEAK HEIGHT = ', \\\n",
    "#             max(acf_per_height[:2]), 'LOCAL PEAK HEIGHT = ', lh1[x])\n",
    "\n",
    "        t_stats = atpy.Table()\n",
    "        t_stats.add_column('acf_per_pos', acf_per_pos)\n",
    "        t_stats.add_column('acf_per_height', acf_per_height)\n",
    "        t_stats.add_column('acf_per_err', acf_per_err)\n",
    "        t_stats.add_column('asym', asym)\n",
    "        t_stats.add_column('locheight', locheight)\n",
    "\n",
    "        if dlag_per_err[x] == 0.:\n",
    "             error = acf_per_err[x]\n",
    "        else: error = dlag_per_err[x]\n",
    "\n",
    "        print('PERIOD = ', period[x], '+/-', error)\n",
    "        print('saving as', '%s/%s_result.txt'%(savedir, id_list[0]))\n",
    "        np.savetxt('%s/%s_result.txt'%(savedir, id_list[0]),\n",
    "                   np.transpose((period[x], error)))\n",
    "    else:\n",
    "        blank = np.array([0,0])\n",
    "#         np.savetxt('%s/%s_result.txt' %(savedir, id_list[0]), blank)\n",
    "\n",
    "    t = atpy.Table()\n",
    "    t.add_column('period', period) #period\n",
    "    t.add_column('sine_per', sine_per) #sine period\n",
    "    t.add_column('sine_height', sine_height)\n",
    "    t.add_column('acf_peak_per', acf_peak_per)\n",
    "    t.add_column('med_dlag_per', med_dlag_per)\n",
    "    t.add_column('dlag_per_err', dlag_per_err) #error\n",
    "    t.add_column('h1', h1)\n",
    "    t.add_column('w1', w1)\n",
    "    t.add_column('lh1', lh1)\n",
    "    t.add_column('hlocgrad', hlocgrad)\n",
    "    t.add_column('hloc_grad_scatter', hloc_grad_scatter)\n",
    "    t.add_column('width_grad', width_grad)\n",
    "    t.add_column('width_grad_scatter', width_grad_scatter)\n",
    "    t.add_column('num_of_peaks', num_of_peaks)\n",
    "    t.add_column('harmonic_det', harmonic_det)\n",
    "    t.add_column('amp_all', amp_all)\n",
    "    t.add_column('amp_per', amp_per)\n",
    "    return period, dlag_per_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACF calc function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acf_calc(time, flux, interval, kid, max_psearch_len):\n",
    "\n",
    "    ''' Calculate ACF, calls error calc function'''\n",
    "\n",
    "    # ACF calculation in pylab, close fig when finished\n",
    "    pylab.figure(50)\n",
    "    pylab.clf()\n",
    "    lags, acf, lines, axis = pylab.acorr(flux, maxlags = max_psearch_len)\n",
    "    pylab.close(50)\n",
    "    #acf = dan_acf(flux)\n",
    "\n",
    "    #convolve smoothing window with Gaussian kernel\n",
    "    gauss_func = lambda x,sig: 1./np.sqrt(2*np.pi*sig**2) * \\\n",
    "                 np.exp(-0.5*(x**2)/(sig**2)) #define a Gaussian\n",
    "    #create the smoothing kernel\n",
    "    conv_func = gauss_func(np.arange(-28,28,1.),9.)\n",
    "\n",
    "    acf_smooth = np.convolve(acf,conv_func,mode='same') #and convolve\n",
    "    lenlag = len(lags)\n",
    "    lags = lags[int(lenlag/2.0):lenlag][:-1] * interval\n",
    "    acf = acf[int(lenlag/2.0): lenlag][0:-1]\n",
    "    acf_smooth = acf_smooth[int(lenlag/2.0): lenlag][1:]\n",
    "\n",
    "    # find max using usmoothed acf (for plot only)\n",
    "    max_ind_us, max_val_us = extrema(acf, max = True, min = False)\n",
    "\n",
    "    # find max/min using smoothed acf\n",
    "    max_ind_s, max_val_s = extrema(acf_smooth, max = True, min = False)\n",
    "    min_ind_s, min_val_s = extrema(acf_smooth, max = False, min = True)\n",
    "    maxmin_ind_s, maxmin_val_s = extrema(acf_smooth, max = True, min = True)\n",
    "\n",
    "    if len(max_ind_s) > 0 and len(min_ind_s) > 0:\n",
    "        # ensure no duplicate peaks are detected\n",
    "        t_max_s = atpy.Table()\n",
    "        t_max_s.add_column('ind', max_ind_s)\n",
    "        t_max_s.add_column('val', max_val_s)\n",
    "        t_min_s = atpy.Table()\n",
    "        t_min_s.add_column('ind', min_ind_s)\n",
    "        t_min_s.add_column('val', min_val_s)\n",
    "        t_maxmin_s = atpy.Table()\n",
    "        t_maxmin_s.add_column('ind', maxmin_ind_s)\n",
    "        t_maxmin_s.add_column('val', maxmin_val_s)\n",
    "\n",
    "        ma_i = collections.Counter(t_max_s.ind)\n",
    "        dup_arr = [i for i in ma_i if ma_i[i]>1]\n",
    "        if len(dup_arr) > 0:\n",
    "            for j in scipy.arange(len(dup_arr)):\n",
    "                tin = t_max_s.where(t_max_s.ind != dup_arr[j])\n",
    "                tout = t_max_s.where(t_max_s.ind == dup_arr[j])\n",
    "                tout = tout.rows([0])\n",
    "                tin.append(tout)\n",
    "            t_max_s = copy.deepcopy(tin)\n",
    "\n",
    "        ma_i = collections.Counter(t_min_s.ind)\n",
    "        dup_arr = [i for i in ma_i if ma_i[i]>1]\n",
    "        if len(dup_arr) > 0:\n",
    "            for j in scipy.arange(len(dup_arr)):\n",
    "                tin = t_min_s.where(t_min_s.ind != dup_arr[j])\n",
    "                tout = t_min_s.where(t_min_s.ind == dup_arr[j])\n",
    "                tout = tout.rows([0])\n",
    "                tin.append(tout)\n",
    "            t_min_s = copy.deepcopy(tin)\n",
    "\n",
    "        ma_i = collections.Counter(t_maxmin_s.ind)\n",
    "        dup_arr = [i for i in ma_i if ma_i[i]>1]\n",
    "        if len(dup_arr) > 0:\n",
    "            for j in scipy.arange(len(dup_arr)):\n",
    "                tin = t_maxmin_s.where(t_maxmin_s.ind != dup_arr[j])\n",
    "                tout = t_maxmin_s.where(t_maxmin_s.ind == dup_arr[j])\n",
    "                tout = tout.rows([0])\n",
    "                tin.append(tout)\n",
    "            t_maxmin_s = copy.deepcopy(tin)\n",
    "\n",
    "        t_max_s.sort('ind')\n",
    "        t_min_s.sort('ind')\n",
    "        t_maxmin_s.sort('ind')\n",
    "\n",
    "        # relate max inds to lags\n",
    "        maxnum = len(t_max_s.ind)\n",
    "        acf_per_pos = lags[t_max_s.ind]\n",
    "        acf_per_height = acf[t_max_s.ind]\n",
    "\n",
    "        print('Calculating errors and asymmetries...')\n",
    "        # Calculate peak widths, asymmetries etc\n",
    "        acf_per_err, locheight, asym= \\\n",
    "            calc_err(kid = kid, lags = lags, acf = acf, inds = \\\n",
    "            t_maxmin_s.ind, vals = t_maxmin_s.val, maxnum = maxnum)\n",
    "\n",
    "    else:\n",
    "        acf_per_pos = scipy.array([-9999])\n",
    "        acf_per_height = scipy.array([-9999])\n",
    "        acf_per_err = scipy.array([-9999])\n",
    "        locheight = scipy.array([-9999])\n",
    "        asym = scipy.array([-9999])\n",
    "\n",
    "    # save corrected LC and ACF\n",
    "    t_lc = atpy.Table()\n",
    "    t_lc.add_column('time', time)\n",
    "    t_lc.add_column('flux', flux)\n",
    "\n",
    "    t_acf = atpy.Table()\n",
    "    t_acf.add_column('lags_days', lags)\n",
    "    t_acf.add_column('acf', acf)\n",
    "    t_acf.add_column('acf_smooth', acf_smooth)\n",
    "\n",
    "    pylab.figure(6,(10, 5.5))\n",
    "    pylab.clf()\n",
    "    pylab.plot(t_acf.lags_days, t_acf.acf, 'k-')\n",
    "    pylab.plot(t_acf.lags_days, t_acf.acf_smooth, 'r-')\n",
    "    for j in scipy.arange(len(max_ind_us)):\n",
    "        pylab.axvline(t_acf.lags_days[max_ind_us[j]], ls = '--', c = 'k', lw=1)\n",
    "    for i in scipy.arange(len(acf_per_pos)):\n",
    "        pylab.axvline(acf_per_pos[i], ls = '--', c = 'r', lw = 2)\n",
    "    if t_acf.lags_days.max() > 10 * acf_per_pos[0]:\n",
    "        pylab.xlim(0,10 * acf_per_pos[0])\n",
    "    else: pylab.xlim(0,max(t_acf.lags_days))\n",
    "    pylab.xlabel('Period (days)')\n",
    "    pylab.ylabel('ACF')\n",
    "    pylab.title('ID: %s, Smoothed \\& Unsmoothed ACF' %(kid))\n",
    "    return  t_acf, acf_per_pos, acf_per_height, acf_per_err, locheight, asym"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
